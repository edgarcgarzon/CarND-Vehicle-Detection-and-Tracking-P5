{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Project\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Color transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, color_space='BGR'):\n",
    "        # Convert image to new color space (if specified)\n",
    "    if color_space != 'BGR':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == 'RGB':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    else: \n",
    "        feature_image = np.copy(img)             \n",
    "\n",
    "    # Return the feature vector\n",
    "    return feature_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Spatial binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Color histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Extract feature from one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a limage\n",
    "def img_features(feature_image, spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel, spatial_size):\n",
    "    file_features = []\n",
    "    \n",
    "    #Spatial feature extraction\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        file_features.append(spatial_features)\n",
    "    \n",
    "    #Color feature extraction\n",
    "    if hist_feat == True:\n",
    "        # Apply color_hist()\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        file_features.append(hist_features)\n",
    "    \n",
    "    #HOG feature extraction\n",
    "    if hog_feat == True:\n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append the new feature vector to the features list\n",
    "        file_features.append(hog_features)\n",
    "    return file_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Feature extraction for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='BGR', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    \n",
    "    # Iterate through the list of images\n",
    "    for file_p in imgs:\n",
    "        \n",
    "        file_features = []\n",
    "        \n",
    "        # Read in each imageone by one\n",
    "        image = cv2.imread(file_p)\n",
    "        \n",
    "        # apply color conversion if other than 'BGR'\n",
    "        feature_image = convert_color(image, color_space=cspace)\n",
    "        \n",
    "        #Get the features\n",
    "        file_features = img_features(feature_image, spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel, spatial_size)\n",
    "        \n",
    "        #Append features to the list \n",
    "        features.append(np.concatenate(file_features))\n",
    "        \n",
    "        #Get the features and append features of flip image for augmentation\n",
    "        feature_image=cv2.flip(feature_image,1) \n",
    "        file_features = img_features(feature_image, spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel, spatial_size)\n",
    "        \n",
    "        features.append(np.concatenate(file_features))\n",
    "        \n",
    "    return features # Return list of feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicle images:  8968\n",
      "Number of non-vehicle images:  8792\n"
     ]
    }
   ],
   "source": [
    "images = glob.iglob('Features/**/*.png', recursive=True)\n",
    "\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "for image in images:\n",
    "    if 'non' in image:\n",
    "        notcars.append(image)\n",
    "    else:\n",
    "        cars.append(image)\n",
    "\n",
    "print(\"Number of vehicle images: \", len(notcars))\n",
    "print(\"Number of non-vehicle images: \", len(cars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorspace = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "#sample_size = 500\n",
    "#cars = cars[0:sample_size]\n",
    "#notcars = notcars[0:sample_size]\n",
    "\n",
    "#Extract the car features\n",
    "car_features = extract_features(cars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, \n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True)\n",
    "\n",
    "#Extract the non-cars features\n",
    "notcar_features = extract_features(notcars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True)\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)    \n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (28416, 96)\n",
      "Validation data shape:  (7104, 96)\n"
     ]
    }
   ],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=rand_state)\n",
    "\n",
    "print(\"Train data shape: \", X_train.shape)\n",
    "print(\"Validation data shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Train the clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.49 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9207\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:VehicleDetection]",
   "language": "python",
   "name": "conda-env-VehicleDetection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
